{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import base64\n",
    "import pandas as pd\n",
    "import re\n",
    "from supabase import create_client\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# for job page scraper\n",
    "from bs4 import BeautifulSoup\n",
    "import openai\n",
    "from time import sleep\n",
    "import json\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make GET request to job board README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_github_readme():\n",
    "    url = \"https://api.github.com/repos/SimplifyJobs/Summer2025-Internships/contents/README.md\"\n",
    "    #url = \"https://api.github.com/repos/SimplifyJobs/New-Grad-Positions/contents/README.md\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        content = response.json()['content']\n",
    "        decoded_content = base64.b64decode(content).decode('utf-8')\n",
    "        return decoded_content\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_url_from_html(html_string):\n",
    "    # Extract URL from href attribute\n",
    "    url_match = re.search(r'href=\"([^\"]+)\"', html_string)\n",
    "    if url_match:\n",
    "        return url_match.group(1)\n",
    "    return html_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract table data from HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_table_data(markdown_content):\n",
    "    # Find the table in the markdown content\n",
    "    table_pattern = r'\\| Company \\| Role \\| Location \\| Application\\/Link \\| Date Posted \\|\\n\\|[^\\n]+\\n((?:\\|[^\\n]+\\n)*)'\n",
    "    match = re.search(table_pattern, markdown_content)\n",
    "    \n",
    "    if match:\n",
    "        table_content = match.group(0)\n",
    "        \n",
    "        # Convert markdown table to list of lists\n",
    "        rows = table_content.split('\\n')\n",
    "        # Remove empty rows and the separator row (|----|)\n",
    "        rows = [row for row in rows if row.strip() and not row.strip().startswith('|-')]\n",
    "        \n",
    "        # Parse each row\n",
    "        data = []\n",
    "        for row in rows[1:]:  # Skip header row\n",
    "            # Split by | and remove empty strings\n",
    "            cols = [col.strip() for col in row.split('|') if col.strip()]\n",
    "            \n",
    "            # Skip rows that don't have enough columns or contain only dashes\n",
    "            # Skip rows that don't have enough columns or contain only dashes\n",
    "            if len(cols) < 4 or all(c.replace('-', '').strip() == '' for c in cols) or any(c.strip() == '---' for c in cols):\n",
    "                continue\n",
    "                \n",
    "            # Clean up the company name (extract just the name from markdown link)\n",
    "            company_raw = cols[0]\n",
    "            # Extract company name from markdown link if present, otherwise use as is\n",
    "            company_match = re.search(r'\\[([^\\]]+)\\]', company_raw)\n",
    "            company = company_match.group(1) if company_match else company_raw.replace('*', '')\n",
    "            \n",
    "            # Extract URL from HTML link\n",
    "            application_link = extract_url_from_html(cols[3])\n",
    "            \n",
    "            # Create row data with safe indexing\n",
    "            data.append({\n",
    "                'Company': company,\n",
    "                'Role': cols[1] if len(cols) > 1 else '',\n",
    "                'Location': cols[2] if len(cols) > 2 else '',\n",
    "                'Application_Link': application_link,\n",
    "                'Date_Posted': cols[4] if len(cols) > 4 else ''\n",
    "            })\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "    \n",
    "    return None\n",
    "\n",
    "def extract_table_data_today(markdown_content):\n",
    "    # Find the table in the markdown content\n",
    "    table_pattern = r'\\| Company \\| Role \\| Location \\| Application\\/Link \\| Date Posted \\|\\n\\|[^\\n]+\\n((?:\\|[^\\n]+\\n)*)'\n",
    "    match = re.search(table_pattern, markdown_content)\n",
    "    \n",
    "    if match:\n",
    "        table_content = match.group(0)\n",
    "        \n",
    "        # Convert markdown table to list of lists\n",
    "        rows = table_content.split('\\n')\n",
    "        # Remove empty rows and the separator row (|----|)\n",
    "        rows = [row for row in rows if row.strip() and not row.strip().startswith('|-')]\n",
    "        \n",
    "        # Parse each row\n",
    "        data = []\n",
    "        for row in rows[1:]:  # Skip header row\n",
    "            # Split by | and remove empty strings\n",
    "            cols = [col.strip() for col in row.split('|') if col.strip()]\n",
    "            \n",
    "            # Skip rows that don't have enough columns or contain only dashes\n",
    "            if len(cols) < 4 or all(c.replace('-', '').strip() == '' for c in cols):\n",
    "                continue\n",
    "                \n",
    "            # Clean up the company name (remove ** if present)\n",
    "            company = cols[0].replace('*', '')\n",
    "            \n",
    "            # Extract URL from HTML link\n",
    "            application_link = extract_url_from_html(cols[3])\n",
    "            \n",
    "            # Create row data with safe indexing\n",
    "            data.append({\n",
    "                'Company': company,\n",
    "                'Role': cols[1] if len(cols) > 1 else '',\n",
    "                'Location': cols[2] if len(cols) > 2 else '',\n",
    "                'Application_Link': application_link,\n",
    "                'Date_Posted': cols[4] if len(cols) > 4 else ''\n",
    "            })\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Filter for today's date\n",
    "        today = datetime.now().strftime('%b %d')\n",
    "        df = df[df['Date_Posted'] == today]\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open job page website, scrape text, and run through GPT to output job details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_job_data(df, max_workers=10):\n",
    "    \"\"\"\n",
    "    Enrich job data using multithreading to process multiple jobs concurrently.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing job listings\n",
    "        max_workers: Maximum number of concurrent threads (default: 10)\n",
    "    \"\"\"\n",
    "    from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    # Create a copy of the DataFrame\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Initialize OpenAI client\n",
    "    client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "    \n",
    "    # Initialize columns\n",
    "    df['company_formatted'] = ''\n",
    "    df['description'] = ''\n",
    "    df['soft_skills'] = ''\n",
    "    df['technical_skills'] = ''\n",
    "    df['experience_level'] = ''\n",
    "    \n",
    "    def process_single_job(row_data):\n",
    "        \"\"\"Process a single job listing\"\"\"\n",
    "        index, row = row_data\n",
    "        \n",
    "        try:\n",
    "            # Skip rows with \"â†³\" as company name\n",
    "            if row['Company'].strip() == \"â†³\":\n",
    "                return index, {\n",
    "                    'status': 'skipped',\n",
    "                    'message': 'Duplicate entry',\n",
    "                    'data': None\n",
    "                }\n",
    "                \n",
    "            # Skip if application link contains ðŸ”’\n",
    "            if \"ðŸ”’\" in str(row['Application_Link']):\n",
    "                return index, {\n",
    "                    'status': 'skipped',\n",
    "                    'message': 'Locked job posting',\n",
    "                    'data': None\n",
    "                }\n",
    "\n",
    "            # Headers to mimic a browser request\n",
    "            headers = {\n",
    "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "            }\n",
    "\n",
    "            # Get the webpage content\n",
    "            response = requests.get(\n",
    "                row['Application_Link'],\n",
    "                headers=headers,\n",
    "                timeout=10,\n",
    "                verify=False\n",
    "            )\n",
    "            \n",
    "            if response.status_code != 200:\n",
    "                return index, {\n",
    "                    'status': 'error',\n",
    "                    'message': f'Failed to fetch webpage: Status code {response.status_code}',\n",
    "                    'data': None\n",
    "                }\n",
    "\n",
    "            # Parse the webpage content\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Remove scripts and styles\n",
    "            for script in soup([\"script\", \"style\"]):\n",
    "                script.decompose()\n",
    "            \n",
    "            # Extract and clean text\n",
    "            text = soup.get_text()\n",
    "            lines = (line.strip() for line in text.splitlines())\n",
    "            chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "            text = ' '.join(chunk for chunk in chunks if chunk)\n",
    "            \n",
    "            if not text.strip():\n",
    "                return index, {\n",
    "                    'status': 'error',\n",
    "                    'message': 'No text content found',\n",
    "                    'data': None\n",
    "                }\n",
    "\n",
    "            # Prepare prompt for GPT\n",
    "            prompt = f\"\"\"\n",
    "            Please analyze this job posting and extract the following information in JSON format:\n",
    "\n",
    "            Job Description: {text[:4000]}\n",
    "\n",
    "            Return a valid JSON object with exactly these fields:\n",
    "            {{\n",
    "                \"company_formatted\": \"The name of the company\",\n",
    "                \"description\": \"A concise summary of the job posting\",\n",
    "                \"soft_skills\": [\"skill1\", \"skill2\", ...],\n",
    "                \"technical_skills\": [\"skill1\", \"skill2\", ...],\n",
    "                \"experience_level\": \"one of: beginner, intermediate, advanced\"\n",
    "            }}\n",
    "            \"\"\"\n",
    "            \n",
    "            # Make OpenAI API call\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant that analyzes job postings and extracts key information in strict JSON format.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            # Process the response\n",
    "            response_content = response.choices[0].message.content.strip()\n",
    "            \n",
    "            # Remove code fences if present\n",
    "            if response_content.startswith(\"```\") and response_content.endswith(\"```\"):\n",
    "                response_content = response_content[3:]\n",
    "                if '\\n' in response_content:\n",
    "                    first_line, rest = response_content.split('\\n', 1)\n",
    "                    if re.match(r'^\\w+$', first_line.strip()):\n",
    "                        response_content = rest\n",
    "                if response_content.endswith(\"```\"):\n",
    "                    response_content = response_content[:-3]\n",
    "            response_content = response_content.strip()\n",
    "            \n",
    "            # Parse JSON response\n",
    "            parsed_data = json.loads(response_content)\n",
    "            \n",
    "            return index, {\n",
    "                'status': 'success',\n",
    "                'message': 'Successfully processed',\n",
    "                'data': parsed_data\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            return index, {\n",
    "                'status': 'error',\n",
    "                'message': str(e),\n",
    "                'data': None\n",
    "            }\n",
    "\n",
    "    # Process jobs in parallel\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit all jobs\n",
    "        future_to_job = {\n",
    "            executor.submit(process_single_job, (index, row)): (index, row) \n",
    "            for index, row in df.iterrows()\n",
    "        }\n",
    "        \n",
    "        # Process completed jobs\n",
    "        for future in as_completed(future_to_job):\n",
    "            index, result = future.result()\n",
    "            \n",
    "            # Print progress\n",
    "            print(f\"\\nProcessing job {index + 1}/{len(df)}: {df.iloc[index]['Company']} - {df.iloc[index]['Role']}\")\n",
    "            print(f\"Status: {result['status']} - {result['message']}\")\n",
    "            \n",
    "            # Update DataFrame if processing was successful\n",
    "            if result['status'] == 'success' and result['data']:\n",
    "                parsed_data = result['data']\n",
    "                df.loc[index, 'company_formatted'] = parsed_data.get('company_formatted', '')\n",
    "                df.loc[index, 'description'] = parsed_data.get('description', '')\n",
    "                df.loc[index, 'soft_skills'] = ', '.join(parsed_data.get('soft_skills', []))\n",
    "                df.loc[index, 'technical_skills'] = ', '.join(parsed_data.get('technical_skills', []))\n",
    "                df.loc[index, 'experience_level'] = parsed_data.get('experience_level', '')\n",
    "            \n",
    "            # Add small delay to respect rate limits\n",
    "            sleep(0.1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Role</th>\n",
       "      <th>Location</th>\n",
       "      <th>Application_Link</th>\n",
       "      <th>Date_Posted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Xometry</td>\n",
       "      <td>Software Engineer â€“ Intern</td>\n",
       "      <td>Lexington, KY&lt;/br&gt;North Bethesda, MD</td>\n",
       "      <td>https://job-boards.greenhouse.io/xometry/jobs/...</td>\n",
       "      <td>Dec 16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>â†³</td>\n",
       "      <td>Software Engineer â€“ Intern</td>\n",
       "      <td>North Bethesda, MD</td>\n",
       "      <td>https://job-boards.greenhouse.io/xometry/jobs/...</td>\n",
       "      <td>Dec 16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>â†³</td>\n",
       "      <td>Machine Learning Intern</td>\n",
       "      <td>Lexington, KY&lt;/br&gt;North Bethesda, MD</td>\n",
       "      <td>https://job-boards.greenhouse.io/xometry/jobs/...</td>\n",
       "      <td>Dec 16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>â†³</td>\n",
       "      <td>Machine Learning Intern</td>\n",
       "      <td>Lexington, KY&lt;/br&gt;North Bethesda, MD</td>\n",
       "      <td>https://job-boards.greenhouse.io/xometry/jobs/...</td>\n",
       "      <td>Dec 16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>â†³</td>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>North Bethesda, MD</td>\n",
       "      <td>https://job-boards.greenhouse.io/xometry/jobs/...</td>\n",
       "      <td>Dec 16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Company                        Role                              Location  \\\n",
       "0  Xometry  Software Engineer â€“ Intern  Lexington, KY</br>North Bethesda, MD   \n",
       "1        â†³  Software Engineer â€“ Intern                    North Bethesda, MD   \n",
       "2        â†³     Machine Learning Intern  Lexington, KY</br>North Bethesda, MD   \n",
       "3        â†³     Machine Learning Intern  Lexington, KY</br>North Bethesda, MD   \n",
       "4        â†³         Data Science Intern                    North Bethesda, MD   \n",
       "\n",
       "                                    Application_Link Date_Posted  \n",
       "0  https://job-boards.greenhouse.io/xometry/jobs/...      Dec 16  \n",
       "1  https://job-boards.greenhouse.io/xometry/jobs/...      Dec 16  \n",
       "2  https://job-boards.greenhouse.io/xometry/jobs/...      Dec 16  \n",
       "3  https://job-boards.greenhouse.io/xometry/jobs/...      Dec 16  \n",
       "4  https://job-boards.greenhouse.io/xometry/jobs/...      Dec 16  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readme_content = get_github_readme()\n",
    "df = extract_table_data(readme_content)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_recent_jobs(df):\n",
    "    \"\"\"\n",
    "    Filter jobs that were posted today or on December 15th and handle arrow notation\n",
    "    for multiple jobs from the same company.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing job listings with 'Date_Posted' column\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame containing only jobs from today or December 15th with proper company names\n",
    "    \"\"\"\n",
    "    # Get today's date in 'MMM DD' format\n",
    "    today = datetime.now().strftime('%b %d')\n",
    "    \n",
    "    # Filter for today's date or Dec 15\n",
    "    mask = (df['Date_Posted'] == today) | (df['Date_Posted'] == 'Dec 15')\n",
    "    filtered_df = df[mask].copy()\n",
    "    \n",
    "    # Reset index\n",
    "    filtered_df = filtered_df.reset_index(drop=True)\n",
    "    \n",
    "    # Handle arrow notation by filling company names\n",
    "    last_company = None\n",
    "    for idx in filtered_df.index:\n",
    "        if filtered_df.loc[idx, 'Company'].strip() == \"â†³\":\n",
    "            if last_company is not None:\n",
    "                filtered_df.loc[idx, 'Company'] = last_company\n",
    "        else:\n",
    "            last_company = filtered_df.loc[idx, 'Company']\n",
    "    \n",
    "    print(f\"Filtered to {len(filtered_df)} jobs from today ({today}) or Dec 15\")\n",
    "    \n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered to 14 jobs from today (Dec 16) or Dec 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Role</th>\n",
       "      <th>Location</th>\n",
       "      <th>Application_Link</th>\n",
       "      <th>Date_Posted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Xometry</td>\n",
       "      <td>Software Engineer â€“ Intern</td>\n",
       "      <td>Lexington, KY&lt;/br&gt;North Bethesda, MD</td>\n",
       "      <td>https://job-boards.greenhouse.io/xometry/jobs/...</td>\n",
       "      <td>Dec 16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Xometry</td>\n",
       "      <td>Software Engineer â€“ Intern</td>\n",
       "      <td>North Bethesda, MD</td>\n",
       "      <td>https://job-boards.greenhouse.io/xometry/jobs/...</td>\n",
       "      <td>Dec 16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xometry</td>\n",
       "      <td>Machine Learning Intern</td>\n",
       "      <td>Lexington, KY&lt;/br&gt;North Bethesda, MD</td>\n",
       "      <td>https://job-boards.greenhouse.io/xometry/jobs/...</td>\n",
       "      <td>Dec 16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xometry</td>\n",
       "      <td>Machine Learning Intern</td>\n",
       "      <td>Lexington, KY&lt;/br&gt;North Bethesda, MD</td>\n",
       "      <td>https://job-boards.greenhouse.io/xometry/jobs/...</td>\n",
       "      <td>Dec 16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xometry</td>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>North Bethesda, MD</td>\n",
       "      <td>https://job-boards.greenhouse.io/xometry/jobs/...</td>\n",
       "      <td>Dec 16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Company                        Role                              Location  \\\n",
       "0  Xometry  Software Engineer â€“ Intern  Lexington, KY</br>North Bethesda, MD   \n",
       "1  Xometry  Software Engineer â€“ Intern                    North Bethesda, MD   \n",
       "2  Xometry     Machine Learning Intern  Lexington, KY</br>North Bethesda, MD   \n",
       "3  Xometry     Machine Learning Intern  Lexington, KY</br>North Bethesda, MD   \n",
       "4  Xometry         Data Science Intern                    North Bethesda, MD   \n",
       "\n",
       "                                    Application_Link Date_Posted  \n",
       "0  https://job-boards.greenhouse.io/xometry/jobs/...      Dec 16  \n",
       "1  https://job-boards.greenhouse.io/xometry/jobs/...      Dec 16  \n",
       "2  https://job-boards.greenhouse.io/xometry/jobs/...      Dec 16  \n",
       "3  https://job-boards.greenhouse.io/xometry/jobs/...      Dec 16  \n",
       "4  https://job-boards.greenhouse.io/xometry/jobs/...      Dec 16  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = filter_recent_jobs(df)\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing job 9/14: Aurora Innovation - Software Engineering Intern\n",
      "Status: error - No text content found\n",
      "\n",
      "Processing job 8/14: Leidos - Cyber AI Intern\n",
      "Status: error - No text content found\n",
      "\n",
      "Processing job 10/14: Assurant - AI/Data Science Intern\n",
      "Status: error - No text content found\n",
      "\n",
      "Processing job 11/14: Assurant - Business Integration Data Analytics Intern\n",
      "Status: error - No text content found\n",
      "\n",
      "Processing job 7/14: Manulife Financial - Financial Investment Analyst Co-op/Intern\n",
      "Status: error - No text content found\n",
      "\n",
      "Processing job 12/14: Zoox - Developer Platforms Intern\n",
      "Status: success - Successfully processed\n",
      "\n",
      "Processing job 6/14: Xometry - Data Science Intern\n",
      "Status: success - Successfully processed\n",
      "\n",
      "Processing job 13/14: Astranis Space Technologies - DevOps Engineer (Flight Software) - Intern ðŸ‡ºðŸ‡¸\n",
      "Status: success - Successfully processed\n",
      "\n",
      "Processing job 3/14: Xometry - Machine Learning Intern\n",
      "Status: success - Successfully processed\n",
      "\n",
      "Processing job 4/14: Xometry - Machine Learning Intern\n",
      "Status: success - Successfully processed\n",
      "\n",
      "Processing job 2/14: Xometry - Software Engineer â€“ Intern\n",
      "Status: success - Successfully processed\n",
      "\n",
      "Processing job 5/14: Xometry - Data Science Intern\n",
      "Status: success - Successfully processed\n",
      "\n",
      "Processing job 14/14: ABB - Data Science Intern- Summer 2025\n",
      "Status: success - Successfully processed\n",
      "\n",
      "Processing job 1/14: Xometry - Software Engineer â€“ Intern\n",
      "Status: success - Successfully processed\n"
     ]
    }
   ],
   "source": [
    "#enriched_jobs = enrich_job_data(df)  \n",
    "filtered_enriched_jobs = enrich_job_data(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Role</th>\n",
       "      <th>Location</th>\n",
       "      <th>Application_Link</th>\n",
       "      <th>Date_Posted</th>\n",
       "      <th>company_formatted</th>\n",
       "      <th>description</th>\n",
       "      <th>soft_skills</th>\n",
       "      <th>technical_skills</th>\n",
       "      <th>experience_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Xometry</td>\n",
       "      <td>Software Engineer â€“ Intern</td>\n",
       "      <td>Lexington, KY&lt;/br&gt;North Bethesda, MD</td>\n",
       "      <td>https://job-boards.greenhouse.io/xometry/jobs/...</td>\n",
       "      <td>Dec 16</td>\n",
       "      <td>Xometry</td>\n",
       "      <td>Xometry is offering a Software Engineer Intern...</td>\n",
       "      <td>Excellent Communication Skills, Strong Work Et...</td>\n",
       "      <td>Software Development, Version Control, Debuggi...</td>\n",
       "      <td>beginner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Xometry</td>\n",
       "      <td>Software Engineer â€“ Intern</td>\n",
       "      <td>North Bethesda, MD</td>\n",
       "      <td>https://job-boards.greenhouse.io/xometry/jobs/...</td>\n",
       "      <td>Dec 16</td>\n",
       "      <td>Xometry</td>\n",
       "      <td>Xometry is offering a Software Engineer Intern...</td>\n",
       "      <td>Excellent Communication Skills, Strong Work Et...</td>\n",
       "      <td>Software Development, Version Control, Debuggi...</td>\n",
       "      <td>beginner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xometry</td>\n",
       "      <td>Machine Learning Intern</td>\n",
       "      <td>Lexington, KY&lt;/br&gt;North Bethesda, MD</td>\n",
       "      <td>https://job-boards.greenhouse.io/xometry/jobs/...</td>\n",
       "      <td>Dec 16</td>\n",
       "      <td>Xometry</td>\n",
       "      <td>Xometry is seeking a Machine Learning Intern f...</td>\n",
       "      <td>Strong Work Ethic, Excellent Communication Ski...</td>\n",
       "      <td>Machine Learning, Data Analysis, Model Evaluat...</td>\n",
       "      <td>beginner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xometry</td>\n",
       "      <td>Machine Learning Intern</td>\n",
       "      <td>Lexington, KY&lt;/br&gt;North Bethesda, MD</td>\n",
       "      <td>https://job-boards.greenhouse.io/xometry/jobs/...</td>\n",
       "      <td>Dec 16</td>\n",
       "      <td>Xometry</td>\n",
       "      <td>Xometry is seeking a Machine Learning Intern f...</td>\n",
       "      <td>Excellent Communication Skills, Strong Work Et...</td>\n",
       "      <td>Machine Learning, Data Analysis, Model Evaluat...</td>\n",
       "      <td>beginner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xometry</td>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>North Bethesda, MD</td>\n",
       "      <td>https://job-boards.greenhouse.io/xometry/jobs/...</td>\n",
       "      <td>Dec 16</td>\n",
       "      <td>Xometry</td>\n",
       "      <td>Xometry is seeking a Data Science Intern to ga...</td>\n",
       "      <td>Strong work ethic, Excellent communication ski...</td>\n",
       "      <td>Data analysis, Machine learning, Data wranglin...</td>\n",
       "      <td>beginner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Company                        Role                              Location  \\\n",
       "0  Xometry  Software Engineer â€“ Intern  Lexington, KY</br>North Bethesda, MD   \n",
       "1  Xometry  Software Engineer â€“ Intern                    North Bethesda, MD   \n",
       "2  Xometry     Machine Learning Intern  Lexington, KY</br>North Bethesda, MD   \n",
       "3  Xometry     Machine Learning Intern  Lexington, KY</br>North Bethesda, MD   \n",
       "4  Xometry         Data Science Intern                    North Bethesda, MD   \n",
       "\n",
       "                                    Application_Link Date_Posted  \\\n",
       "0  https://job-boards.greenhouse.io/xometry/jobs/...      Dec 16   \n",
       "1  https://job-boards.greenhouse.io/xometry/jobs/...      Dec 16   \n",
       "2  https://job-boards.greenhouse.io/xometry/jobs/...      Dec 16   \n",
       "3  https://job-boards.greenhouse.io/xometry/jobs/...      Dec 16   \n",
       "4  https://job-boards.greenhouse.io/xometry/jobs/...      Dec 16   \n",
       "\n",
       "  company_formatted                                        description  \\\n",
       "0           Xometry  Xometry is offering a Software Engineer Intern...   \n",
       "1           Xometry  Xometry is offering a Software Engineer Intern...   \n",
       "2           Xometry  Xometry is seeking a Machine Learning Intern f...   \n",
       "3           Xometry  Xometry is seeking a Machine Learning Intern f...   \n",
       "4           Xometry  Xometry is seeking a Data Science Intern to ga...   \n",
       "\n",
       "                                         soft_skills  \\\n",
       "0  Excellent Communication Skills, Strong Work Et...   \n",
       "1  Excellent Communication Skills, Strong Work Et...   \n",
       "2  Strong Work Ethic, Excellent Communication Ski...   \n",
       "3  Excellent Communication Skills, Strong Work Et...   \n",
       "4  Strong work ethic, Excellent communication ski...   \n",
       "\n",
       "                                    technical_skills experience_level  \n",
       "0  Software Development, Version Control, Debuggi...         beginner  \n",
       "1  Software Development, Version Control, Debuggi...         beginner  \n",
       "2  Machine Learning, Data Analysis, Model Evaluat...         beginner  \n",
       "3  Machine Learning, Data Analysis, Model Evaluat...         beginner  \n",
       "4  Data analysis, Machine learning, Data wranglin...         beginner  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#enriched_jobs.head()\n",
    "filtered_enriched_jobs.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter out all jobs where page scraping wasn't succesful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 14 to 9 successfully scraped jobs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Role</th>\n",
       "      <th>Location</th>\n",
       "      <th>Application_Link</th>\n",
       "      <th>Date_Posted</th>\n",
       "      <th>company_formatted</th>\n",
       "      <th>description</th>\n",
       "      <th>soft_skills</th>\n",
       "      <th>technical_skills</th>\n",
       "      <th>experience_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Xometry</td>\n",
       "      <td>Software Engineer â€“ Intern</td>\n",
       "      <td>Lexington, KY&lt;/br&gt;North Bethesda, MD</td>\n",
       "      <td>https://job-boards.greenhouse.io/xometry/jobs/...</td>\n",
       "      <td>Dec 16</td>\n",
       "      <td>Xometry</td>\n",
       "      <td>Xometry is offering a Software Engineer Intern...</td>\n",
       "      <td>Excellent Communication Skills, Strong Work Et...</td>\n",
       "      <td>Software Development, Version Control, Debuggi...</td>\n",
       "      <td>beginner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Xometry</td>\n",
       "      <td>Software Engineer â€“ Intern</td>\n",
       "      <td>North Bethesda, MD</td>\n",
       "      <td>https://job-boards.greenhouse.io/xometry/jobs/...</td>\n",
       "      <td>Dec 16</td>\n",
       "      <td>Xometry</td>\n",
       "      <td>Xometry is offering a Software Engineer Intern...</td>\n",
       "      <td>Excellent Communication Skills, Strong Work Et...</td>\n",
       "      <td>Software Development, Version Control, Debuggi...</td>\n",
       "      <td>beginner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xometry</td>\n",
       "      <td>Machine Learning Intern</td>\n",
       "      <td>Lexington, KY&lt;/br&gt;North Bethesda, MD</td>\n",
       "      <td>https://job-boards.greenhouse.io/xometry/jobs/...</td>\n",
       "      <td>Dec 16</td>\n",
       "      <td>Xometry</td>\n",
       "      <td>Xometry is seeking a Machine Learning Intern f...</td>\n",
       "      <td>Strong Work Ethic, Excellent Communication Ski...</td>\n",
       "      <td>Machine Learning, Data Analysis, Model Evaluat...</td>\n",
       "      <td>beginner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xometry</td>\n",
       "      <td>Machine Learning Intern</td>\n",
       "      <td>Lexington, KY&lt;/br&gt;North Bethesda, MD</td>\n",
       "      <td>https://job-boards.greenhouse.io/xometry/jobs/...</td>\n",
       "      <td>Dec 16</td>\n",
       "      <td>Xometry</td>\n",
       "      <td>Xometry is seeking a Machine Learning Intern f...</td>\n",
       "      <td>Excellent Communication Skills, Strong Work Et...</td>\n",
       "      <td>Machine Learning, Data Analysis, Model Evaluat...</td>\n",
       "      <td>beginner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xometry</td>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>North Bethesda, MD</td>\n",
       "      <td>https://job-boards.greenhouse.io/xometry/jobs/...</td>\n",
       "      <td>Dec 16</td>\n",
       "      <td>Xometry</td>\n",
       "      <td>Xometry is seeking a Data Science Intern to ga...</td>\n",
       "      <td>Strong work ethic, Excellent communication ski...</td>\n",
       "      <td>Data analysis, Machine learning, Data wranglin...</td>\n",
       "      <td>beginner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Company                        Role                              Location  \\\n",
       "0  Xometry  Software Engineer â€“ Intern  Lexington, KY</br>North Bethesda, MD   \n",
       "1  Xometry  Software Engineer â€“ Intern                    North Bethesda, MD   \n",
       "2  Xometry     Machine Learning Intern  Lexington, KY</br>North Bethesda, MD   \n",
       "3  Xometry     Machine Learning Intern  Lexington, KY</br>North Bethesda, MD   \n",
       "4  Xometry         Data Science Intern                    North Bethesda, MD   \n",
       "\n",
       "                                    Application_Link Date_Posted  \\\n",
       "0  https://job-boards.greenhouse.io/xometry/jobs/...      Dec 16   \n",
       "1  https://job-boards.greenhouse.io/xometry/jobs/...      Dec 16   \n",
       "2  https://job-boards.greenhouse.io/xometry/jobs/...      Dec 16   \n",
       "3  https://job-boards.greenhouse.io/xometry/jobs/...      Dec 16   \n",
       "4  https://job-boards.greenhouse.io/xometry/jobs/...      Dec 16   \n",
       "\n",
       "  company_formatted                                        description  \\\n",
       "0           Xometry  Xometry is offering a Software Engineer Intern...   \n",
       "1           Xometry  Xometry is offering a Software Engineer Intern...   \n",
       "2           Xometry  Xometry is seeking a Machine Learning Intern f...   \n",
       "3           Xometry  Xometry is seeking a Machine Learning Intern f...   \n",
       "4           Xometry  Xometry is seeking a Data Science Intern to ga...   \n",
       "\n",
       "                                         soft_skills  \\\n",
       "0  Excellent Communication Skills, Strong Work Et...   \n",
       "1  Excellent Communication Skills, Strong Work Et...   \n",
       "2  Strong Work Ethic, Excellent Communication Ski...   \n",
       "3  Excellent Communication Skills, Strong Work Et...   \n",
       "4  Strong work ethic, Excellent communication ski...   \n",
       "\n",
       "                                    technical_skills experience_level  \n",
       "0  Software Development, Version Control, Debuggi...         beginner  \n",
       "1  Software Development, Version Control, Debuggi...         beginner  \n",
       "2  Machine Learning, Data Analysis, Model Evaluat...         beginner  \n",
       "3  Machine Learning, Data Analysis, Model Evaluat...         beginner  \n",
       "4  Data analysis, Machine learning, Data wranglin...         beginner  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_successful_jobs(df):\n",
    "    # Create a copy to avoid modifying the original DataFrame\n",
    "    filtered_df = df.copy()\n",
    "    \n",
    "    # Filter rows where none of the enriched columns are blank\n",
    "    filtered_df = filtered_df[\n",
    "        (filtered_df['description'] != '') & \n",
    "        (filtered_df['soft_skills'] != '') & \n",
    "        (filtered_df['technical_skills'] != '') & \n",
    "        (filtered_df['experience_level'] != '')\n",
    "    ]\n",
    "    \n",
    "    # Reset the index\n",
    "    filtered_df = filtered_df.reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Filtered from {len(df)} to {len(filtered_df)} successfully scraped jobs\")\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "#successful_jobs = filter_successful_jobs(enriched_jobs)\n",
    "successful_jobs = filter_successful_jobs(filtered_enriched_jobs)\n",
    "\n",
    "successful_jobs.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embed description, soft_skills, and technical_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(df):\n",
    "    # Create a copy of the DataFrame\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Initialize OpenAI client\n",
    "    client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "    \n",
    "    # Function to get embedding for a text\n",
    "    def get_embedding(text):\n",
    "        try:\n",
    "            response = client.embeddings.create(\n",
    "                model=\"text-embedding-3-small\",\n",
    "                input=text,\n",
    "                encoding_format=\"float\"\n",
    "            )\n",
    "            return response.data[0].embedding\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting embedding: {e}\")\n",
    "            return None\n",
    "\n",
    "    print(\"Creating embeddings...\")\n",
    "    \n",
    "    # Create embeddings for each column\n",
    "    print(\"Processing description embeddings...\")\n",
    "    df['description_embedding'] = df['description'].apply(get_embedding)\n",
    "    \n",
    "    print(\"Processing soft skills embeddings...\")\n",
    "    df['soft_skills_embedding'] = df['soft_skills'].apply(get_embedding)\n",
    "    \n",
    "    print(\"Processing technical skills embeddings...\")\n",
    "    df['technical_skills_embedding'] = df['technical_skills'].apply(get_embedding)\n",
    "    \n",
    "    # Check for any failed embeddings\n",
    "    failed_embeddings = df[df[['description_embedding', 'soft_skills_embedding', 'technical_skills_embedding']].isna().any(axis=1)]\n",
    "    if not failed_embeddings.empty:\n",
    "        print(f\"\\nWarning: {len(failed_embeddings)} rows had failed embeddings\")\n",
    "        print(\"Failed rows:\", failed_embeddings.index.tolist())\n",
    "    \n",
    "    print(\"\\nEmbedding creation complete!\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embeddings...\n",
      "Processing description embeddings...\n",
      "Processing soft skills embeddings...\n",
      "Processing technical skills embeddings...\n",
      "\n",
      "Embedding creation complete!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Role</th>\n",
       "      <th>Location</th>\n",
       "      <th>Application_Link</th>\n",
       "      <th>Date_Posted</th>\n",
       "      <th>company_formatted</th>\n",
       "      <th>description</th>\n",
       "      <th>soft_skills</th>\n",
       "      <th>technical_skills</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>description_embedding</th>\n",
       "      <th>soft_skills_embedding</th>\n",
       "      <th>technical_skills_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Xometry</td>\n",
       "      <td>Software Engineer â€“ Intern</td>\n",
       "      <td>Lexington, KY&lt;/br&gt;North Bethesda, MD</td>\n",
       "      <td>https://job-boards.greenhouse.io/xometry/jobs/...</td>\n",
       "      <td>Dec 16</td>\n",
       "      <td>Xometry</td>\n",
       "      <td>Xometry is offering a Software Engineer Intern...</td>\n",
       "      <td>Excellent Communication Skills, Strong Work Et...</td>\n",
       "      <td>Software Development, Version Control, Debuggi...</td>\n",
       "      <td>beginner</td>\n",
       "      <td>[-0.026039941, 0.076060854, -0.009180593, -0.0...</td>\n",
       "      <td>[0.019527998, 0.008498416, 0.011127942, 0.0706...</td>\n",
       "      <td>[-0.027878236, 0.0073712813, 0.0459366, -0.018...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Xometry</td>\n",
       "      <td>Software Engineer â€“ Intern</td>\n",
       "      <td>North Bethesda, MD</td>\n",
       "      <td>https://job-boards.greenhouse.io/xometry/jobs/...</td>\n",
       "      <td>Dec 16</td>\n",
       "      <td>Xometry</td>\n",
       "      <td>Xometry is offering a Software Engineer Intern...</td>\n",
       "      <td>Excellent Communication Skills, Strong Work Et...</td>\n",
       "      <td>Software Development, Version Control, Debuggi...</td>\n",
       "      <td>beginner</td>\n",
       "      <td>[-0.021437919, 0.06792551, -0.00890696, 0.0040...</td>\n",
       "      <td>[0.019528544, 0.008498654, 0.011102023, 0.0707...</td>\n",
       "      <td>[-0.027878236, 0.0073712813, 0.0459366, -0.018...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xometry</td>\n",
       "      <td>Machine Learning Intern</td>\n",
       "      <td>Lexington, KY&lt;/br&gt;North Bethesda, MD</td>\n",
       "      <td>https://job-boards.greenhouse.io/xometry/jobs/...</td>\n",
       "      <td>Dec 16</td>\n",
       "      <td>Xometry</td>\n",
       "      <td>Xometry is seeking a Machine Learning Intern f...</td>\n",
       "      <td>Strong Work Ethic, Excellent Communication Ski...</td>\n",
       "      <td>Machine Learning, Data Analysis, Model Evaluat...</td>\n",
       "      <td>beginner</td>\n",
       "      <td>[-0.043852724, 0.068717174, 0.02993932, -0.010...</td>\n",
       "      <td>[0.013712582, 0.017062739, 0.0022379586, 0.065...</td>\n",
       "      <td>[-0.0050860946, 0.039739814, 0.049622692, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xometry</td>\n",
       "      <td>Machine Learning Intern</td>\n",
       "      <td>Lexington, KY&lt;/br&gt;North Bethesda, MD</td>\n",
       "      <td>https://job-boards.greenhouse.io/xometry/jobs/...</td>\n",
       "      <td>Dec 16</td>\n",
       "      <td>Xometry</td>\n",
       "      <td>Xometry is seeking a Machine Learning Intern f...</td>\n",
       "      <td>Excellent Communication Skills, Strong Work Et...</td>\n",
       "      <td>Machine Learning, Data Analysis, Model Evaluat...</td>\n",
       "      <td>beginner</td>\n",
       "      <td>[-0.026440741, 0.07427399, 0.038561497, -0.018...</td>\n",
       "      <td>[0.019527998, 0.008498416, 0.011127942, 0.0706...</td>\n",
       "      <td>[0.001851956, 0.035457034, 0.0574806, -0.05227...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xometry</td>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>North Bethesda, MD</td>\n",
       "      <td>https://job-boards.greenhouse.io/xometry/jobs/...</td>\n",
       "      <td>Dec 16</td>\n",
       "      <td>Xometry</td>\n",
       "      <td>Xometry is seeking a Data Science Intern to ga...</td>\n",
       "      <td>Strong work ethic, Excellent communication ski...</td>\n",
       "      <td>Data analysis, Machine learning, Data wranglin...</td>\n",
       "      <td>beginner</td>\n",
       "      <td>[-0.023433575, 0.06328651, 0.012460905, -0.005...</td>\n",
       "      <td>[0.011910585, 0.016993446, 0.0044380203, 0.069...</td>\n",
       "      <td>[-0.019295689, 0.018040877, 0.07585692, -0.046...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Company                        Role                              Location  \\\n",
       "0  Xometry  Software Engineer â€“ Intern  Lexington, KY</br>North Bethesda, MD   \n",
       "1  Xometry  Software Engineer â€“ Intern                    North Bethesda, MD   \n",
       "2  Xometry     Machine Learning Intern  Lexington, KY</br>North Bethesda, MD   \n",
       "3  Xometry     Machine Learning Intern  Lexington, KY</br>North Bethesda, MD   \n",
       "4  Xometry         Data Science Intern                    North Bethesda, MD   \n",
       "\n",
       "                                    Application_Link Date_Posted  \\\n",
       "0  https://job-boards.greenhouse.io/xometry/jobs/...      Dec 16   \n",
       "1  https://job-boards.greenhouse.io/xometry/jobs/...      Dec 16   \n",
       "2  https://job-boards.greenhouse.io/xometry/jobs/...      Dec 16   \n",
       "3  https://job-boards.greenhouse.io/xometry/jobs/...      Dec 16   \n",
       "4  https://job-boards.greenhouse.io/xometry/jobs/...      Dec 16   \n",
       "\n",
       "  company_formatted                                        description  \\\n",
       "0           Xometry  Xometry is offering a Software Engineer Intern...   \n",
       "1           Xometry  Xometry is offering a Software Engineer Intern...   \n",
       "2           Xometry  Xometry is seeking a Machine Learning Intern f...   \n",
       "3           Xometry  Xometry is seeking a Machine Learning Intern f...   \n",
       "4           Xometry  Xometry is seeking a Data Science Intern to ga...   \n",
       "\n",
       "                                         soft_skills  \\\n",
       "0  Excellent Communication Skills, Strong Work Et...   \n",
       "1  Excellent Communication Skills, Strong Work Et...   \n",
       "2  Strong Work Ethic, Excellent Communication Ski...   \n",
       "3  Excellent Communication Skills, Strong Work Et...   \n",
       "4  Strong work ethic, Excellent communication ski...   \n",
       "\n",
       "                                    technical_skills experience_level  \\\n",
       "0  Software Development, Version Control, Debuggi...         beginner   \n",
       "1  Software Development, Version Control, Debuggi...         beginner   \n",
       "2  Machine Learning, Data Analysis, Model Evaluat...         beginner   \n",
       "3  Machine Learning, Data Analysis, Model Evaluat...         beginner   \n",
       "4  Data analysis, Machine learning, Data wranglin...         beginner   \n",
       "\n",
       "                               description_embedding  \\\n",
       "0  [-0.026039941, 0.076060854, -0.009180593, -0.0...   \n",
       "1  [-0.021437919, 0.06792551, -0.00890696, 0.0040...   \n",
       "2  [-0.043852724, 0.068717174, 0.02993932, -0.010...   \n",
       "3  [-0.026440741, 0.07427399, 0.038561497, -0.018...   \n",
       "4  [-0.023433575, 0.06328651, 0.012460905, -0.005...   \n",
       "\n",
       "                               soft_skills_embedding  \\\n",
       "0  [0.019527998, 0.008498416, 0.011127942, 0.0706...   \n",
       "1  [0.019528544, 0.008498654, 0.011102023, 0.0707...   \n",
       "2  [0.013712582, 0.017062739, 0.0022379586, 0.065...   \n",
       "3  [0.019527998, 0.008498416, 0.011127942, 0.0706...   \n",
       "4  [0.011910585, 0.016993446, 0.0044380203, 0.069...   \n",
       "\n",
       "                          technical_skills_embedding  \n",
       "0  [-0.027878236, 0.0073712813, 0.0459366, -0.018...  \n",
       "1  [-0.027878236, 0.0073712813, 0.0459366, -0.018...  \n",
       "2  [-0.0050860946, 0.039739814, 0.049622692, -0.0...  \n",
       "3  [0.001851956, 0.035457034, 0.0574806, -0.05227...  \n",
       "4  [-0.019295689, 0.018040877, 0.07585692, -0.046...  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_embeddings = create_embeddings(successful_jobs)\n",
    "\n",
    "df_with_embeddings.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert jobs to Supabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_jobs_to_supabase(df):\n",
    "    # Initialize Supabase client\n",
    "    supabase_url = os.getenv('SUPABASE_URL')\n",
    "    supabase_key = os.getenv('SUPABASE_ANON_KEY')\n",
    "    supabase = create_client(supabase_url, supabase_key)\n",
    "    \n",
    "    # First, let's insert/update companies\n",
    "    for index, row in df.iterrows():\n",
    "        # Extract company name from markdown link if present\n",
    "        company_name = row['company_formatted']\n",
    "        \n",
    "        # Extract company website from markdown link if present\n",
    "        company_url = re.search(r'\\((https?://[^\\)]+)\\)', row['Company'])\n",
    "        company_url = company_url.group(1) if company_url else None\n",
    "        \n",
    "        # Insert or update company\n",
    "        company_data = {\n",
    "            \"name\": company_name,\n",
    "            \"website_url\": company_url,\n",
    "            \"updated_at\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        # Upsert company (insert if not exists, update if exists)\n",
    "        company_result = supabase.table('companies').upsert(company_data).execute()\n",
    "        \n",
    "        # Get the company id\n",
    "        company_id = company_result.data[0]['id']\n",
    "        \n",
    "        # Handle date parsing with error checking\n",
    "        date_posted = None\n",
    "        if row['Date_Posted']:\n",
    "            try:\n",
    "                date_posted = datetime.strptime(row['Date_Posted'], '%b %d').replace(year=2023).date().isoformat()\n",
    "            except ValueError:\n",
    "                print(f\"Warning: Could not parse date '{row['Date_Posted']}' for job {row['Role']}\")\n",
    "        \n",
    "        # Check if job already exists\n",
    "        existing_job = supabase.table('jobs')\\\n",
    "            .select('*')\\\n",
    "            .eq('company_id', company_id)\\\n",
    "            .eq('title', row['Role'])\\\n",
    "            .eq('application_url', row['Application_Link'])\\\n",
    "            .execute()\n",
    "        \n",
    "        if existing_job.data:\n",
    "            print(f\"Job {row['Role']} for company {company_name} already exists, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Prepare job data including new columns and embeddings\n",
    "        job_data = {\n",
    "            \"company_id\": company_id,\n",
    "            \"title\": row['Role'],\n",
    "            \"location\": row['Location'],\n",
    "            \"application_url\": row['Application_Link'],\n",
    "            \"date_posted\": date_posted,\n",
    "            \"updated_at\": datetime.now().isoformat(),\n",
    "            \n",
    "            # New enriched data columns\n",
    "            \"job_description\": row.get('description', ''),\n",
    "            \"soft_skills\": row.get('soft_skills', ''),\n",
    "            \"technical_skills\": row.get('technical_skills', ''),\n",
    "            \"experience_level\": row.get('experience_level', ''),\n",
    "            \n",
    "            # Vector embeddings\n",
    "            \"description_embedding\": row.get('description_embedding', None),\n",
    "            \"soft_skills_embedding\": row.get('soft_skills_embedding', None),\n",
    "            \"technical_skills_embedding\": row.get('technical_skills_embedding', None)\n",
    "        }\n",
    "        \n",
    "        # Insert job\n",
    "        try:\n",
    "            supabase.table('jobs').insert(job_data).execute()\n",
    "            print(f\"Successfully inserted job {row['Role']} for company {company_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error inserting job {row['Role']} for company {company_name}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully inserted job Software Engineer â€“ Intern for company Xometry\n",
      "Successfully inserted job Software Engineer â€“ Intern for company Xometry\n",
      "Successfully inserted job Machine Learning Intern for company Xometry\n",
      "Successfully inserted job Machine Learning Intern for company Xometry\n",
      "Successfully inserted job Data Science Intern for company Xometry\n",
      "Successfully inserted job Data Science Intern for company Xometry\n",
      "Successfully inserted job Developer Platforms Intern for company Zoox\n",
      "Successfully inserted job DevOps Engineer (Flight Software) - Intern ðŸ‡ºðŸ‡¸ for company Astranis\n",
      "Successfully inserted job Data Science Intern- Summer 2025 for company ABB\n",
      "Successfully processed 9 jobs from today\n"
     ]
    }
   ],
   "source": [
    "if df_with_embeddings is not None:\n",
    "    if not df_with_embeddings.empty:\n",
    "        insert_jobs_to_supabase(df_with_embeddings)\n",
    "        print(f\"Successfully processed {len(df_with_embeddings)} jobs from today\")\n",
    "    else:\n",
    "        print(\"No new jobs found today\")\n",
    "else:\n",
    "    print(\"Error: Could not extract table data from README\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
